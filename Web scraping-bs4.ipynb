{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping the Web\n",
    "\n",
    "## Why Scrape?\n",
    "Sometimes the data you require is not available in a structured, downloadable format. Often the most current data is available only on a web site. This notebook demonstrates how to \"scrape\" data from web sites using several different methods.\n",
    "\n",
    "> If you understand how to web scrape, any available data on the web is a database for you!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Should I use RegeX (regular expressions) to parse web data?**\n",
    "> Although extracting patterned data from a text file is directly in the wheelhouse of RegEx, I recommend *against* using it to parse HTML. Crafting an expression that returns all desired strings while excluding all undesired strings is likely to fail. HTML pages vary widely and will return or exclude data in ways you cannot anticipate. Instead, use a library such as Beautiful Soup, to parse HTML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before Scraping\n",
    "Scraping a web site is not always the best option. Consider the following questions prior to scraping:\n",
    "1. Does the web site in question allow scraping? (check the robots.txt)\n",
    "2. Am I able to adhere to the requests of the web site (again, see robots.txt)?\n",
    "3. Is scraping the easiest, most efficient, or most reliable method? Copy/paste? API? Download data file?\n",
    "4. Is it ethical to scrape this information?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML Knowledge\n",
    "Although it's not necessary to be an HTML expert, having a strong grasp of how HTML works is helpful if you intend to extract information from a web page.\n",
    "\n",
    "There are many HTML tutorials available, but one of the most concise options is W3Schools (https://www.w3schools.com/html/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing Source HTML\n",
    "To determine the best method for extracting data from an HTML page, you must view the HTML. To view HTML using Firefox or Chrome, right-click the page and then click **View page source** (to view the entire page as a flat file) or click **Inspect** (to view an HTML inspection tool to navigate the page elements).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Beautiful Soup\n",
    "Beautiful Soup is a Python library for pulling data out of HTML and XML files. It works with your favorite parser to provide idiomatic ways of navigating, searching, and modifying the parse tree. It commonly saves programmers hours or days of work. (source: https://www.crummy.com/software/BeautifulSoup/bs4/doc/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Beautiful Soup\n",
    "To install the beautiful soup package (bs4) use pip.\n",
    "```\n",
    "pip install bs4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Requests module\n",
    "In addition to the HTML parser (bs4), you also need a method to fetch URLs (uniform resource locators). There are several options available to you. This example uses the requests package.\n",
    "\n",
    "```python\n",
    "import bs4\n",
    "from urllib.request import urlopen as req\n",
    "from bs4 import BeautifulSoup as soup\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Scraping - Quote of the Day\n",
    "Below is an example of how to use Requests and Beautiful Soup to obtain an HTML page and parse it.\n",
    "\n",
    "Start by navigating to the page that you want to scrape and obtaining its URL. For this example, we want to scrape the quoteof the day from WisdomQuotes.com. The URL is: http://wisdomquotes.com/quote-of-the-day/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://wisdomquotes.com/quote-of-the-day/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supply a header to the web server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unless you send a header, a web server may reject your request\n",
    "headers = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36'}\n",
    "\n",
    "#Request page, send headers\n",
    "page_html = requests.get(url, headers=headers)\n",
    "\n",
    "print(page_html.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Quote Of The Day - Wisdom Quotes</title>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use .text to return string (.content returns bytes, .text returns string)\n",
    "page_soup = soup(page_html.content, \"html.parser\")\n",
    "\n",
    "page_soup.title # Print the page title to confirm we have successfully parsed the web page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, inpsect the HTML to find a unique method to identify the information you wish to extract.\n",
    "\n",
    "All quotes are prefaced with \"blockquote\", which makes it easy to filter all the quotes on the page.\n",
    "\n",
    "Use the ```find_all()``` method to return a list of quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = page_soup.find_all(\"blockquote\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The find_all method returns a result set, which can be used like a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.ResultSet'>\n"
     ]
    }
   ],
   "source": [
    "print(type(quotes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<blockquote><p>Somewhere, something incredible is waiting to be known. Sharon Begley</p></blockquote>\n"
     ]
    }
   ],
   "source": [
    "# Print the 5th quote\n",
    "print(quotes[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Men must live and create. Live to the point of tears. Albert Camus\n"
     ]
    }
   ],
   "source": [
    "print(quotes[2].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through the list of quotes and print the text attribute of the element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for quote in quotes:\n",
    "    print(\"-----------------------------------\")\n",
    "    print(quote.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Always give without remembering and always receive without forgetting. Brian Tracy\n",
      "-----------------------------------\n",
      "Successful people are simply those with successful habits. Brian Tracy\n"
     ]
    }
   ],
   "source": [
    "for quote in quotes:\n",
    "    if \"Tracy\" in quote.text:\n",
    "        print(\"-----------------------------------\")\n",
    "        print(quote.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find by tag and class\n",
    "Often the information that you need is not labled by tag alone. For example, if you wanted to extract quotes from GoodReads, you could not use tag alone. All the quotes on the page are within div tags, but are uniquely identifed by class name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.goodreads.com/quotes\"\n",
    "page_html = requests.get(url, headers=headers)\n",
    "page_soup = soup(page_html.text, \"html.parser\")\n",
    "goodread_quotes = page_soup.find_all(\"div\", class_=\"quoteText\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“So many books, so little time.”―Frank Zappa'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goodread_quotes[3].text.replace(\"\\n\",\"\").replace(\"  \",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
